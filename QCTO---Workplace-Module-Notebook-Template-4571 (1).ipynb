{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QCTO - Workplace Module\n",
    "\n",
    "### Project Title: Please Insert your Project Title Here\n",
    "#### Done By: LINDOKUHLE MHLONGO\n",
    "\n",
    "Â© ExploreAI 2024\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#BC> Background Context</a>\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Data Collection and Description</a>\n",
    "\n",
    "<a href=#three>3. Loading Data </a>\n",
    "\n",
    "<a href=#four>4. Data Cleaning and Filtering</a>\n",
    "\n",
    "<a href=#five>5. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#six>6. Modeling </a>\n",
    "\n",
    "<a href=#seven>7. Evaluation and Validation</a>\n",
    "\n",
    "<a href=#eight>8. Final Model</a>\n",
    "\n",
    "<a href=#nine>9. Conclusion and Future Work</a>\n",
    "\n",
    "<a href=#ten>10. References</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " <a id=\"BC\"></a>\n",
    "## **Background Context**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Introduce the project, outline its goals, and explain its significance.\n",
    "* **Details:** Include information about the problem domain, the specific questions or challenges the project aims to address, and any relevant background information that sets the stage for the work.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This study is based on an analysis and forecast of avocado prices in the United States from 2015 to 2024. The availability of clients is also governed by price fluctuations. Once more, at this stage, the economic crisis must be taken into account. Also, the research has produced data analysis that have been cleaned up. Pie conversations and bar graphs were among them. These are a variety of images to help the reader comprehend the investigation of avocado pricing in the United States. Three categories are used to classify avocados: extra-large bags, large bags, and small bags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#one></a>\n",
    "## **Importing Packages**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Set up the Python environment with necessary libraries and tools.\n",
    "* **Details:** List and import all the Python packages that will be used throughout the project such as Pandas for data manipulation, Matplotlib/Seaborn for visualization, scikit-learn for modeling, etc.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries for  Data loading, manipulation and analysis\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "# Displays output inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Libraries for Handing Errors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#two></a>\n",
    "## **Data Collection and Description**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Describe how the data was collected and provide an overview of its characteristics.\n",
    "* **Details:** Mention sources of the data, the methods used for collection (e.g., APIs, web scraping, datasets from repositories), and a general description of the dataset including size, scope, and types of data available (e.g., numerical, categorical).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Dataset is about \"Avocado Prices and Sales Volume 2015-2023 in USA\", we got our data from https://www.kaggle.com,seems to be uploaded by user 'vakhariapujan',it is in a form of a csv file.And was last updated 4 Months Ago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#three></a>\n",
    "## **Loading Data**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Load the data into the notebook for manipulation and analysis.\n",
    "* **Details:** Show the code used to load the data and display the first few rows to give a sense of what the raw data looks like.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Avo_df = pd.read_csv('\\\\Users\\\\lindo\\\\OneDrive\\\\Desktop\\\\Workplace_Lindo\\\\Avocado_HassAvocadoBoard_20152023v1.0.1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#four></a>\n",
    "## **Data Cleaning and Filtering**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Prepare the data for analysis by cleaning and filtering.\n",
    "* **Details:** Include steps for handling missing values, removing outliers, correcting errors, and possibly reducing the data (filtering based on certain criteria or features).\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_values(Avo_df_copy):\n",
    "    \"\"\"\n",
    "    Print the count of null values for each column in a DataFrame.\n",
    "\n",
    "    This function iterates through each column in the DataFrame to check for the presence of null values.\n",
    "    If a column contains null values, it prints the column name along with the number of null values.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The pandas DataFrame to check for null values.\n",
    "\n",
    "    Returns:\n",
    "    None: This function does not return a value; it only prints information.\n",
    "    \"\"\"\n",
    "    for column in Avo_df_copy:\n",
    "        if Avo_df_copy[column].isnull().any():\n",
    "            print('{0} has {1} null values'.format(column, Avo_df_copy[column].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Avo_df_copy = Avo_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmallBags has 12390 null values\n",
      "LargeBags has 12390 null values\n",
      "XLargeBags has 12390 null values\n"
     ]
    }
   ],
   "source": [
    "check_null_values(Avo_df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_duplicate_rows(Avo_df_copy):\n",
    "    \"\"\"\n",
    "    Count the number of duplicate rows in a DataFrame.\n",
    "\n",
    "    This function calculates the total number of duplicate rows in the DataFrame by calling the `duplicated` method,\n",
    "    which marks duplicates as `True`, and then sums these cases.\n",
    "\n",
    "    Parameters:\n",
    "    df_copy (pandas.DataFrame): The DataFrame to check for duplicates.\n",
    "\n",
    "    Returns:\n",
    "    int: The count of duplicate rows.\n",
    "    \"\"\"\n",
    "    duplicate_count = Avo_df_copy.duplicated().sum()\n",
    "    return duplicate_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_duplicate_rows(Avo_df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there missing data in the columns?\n",
      "Date            False\n",
      "AveragePrice    False\n",
      "TotalVolume     False\n",
      "plu4046         False\n",
      "plu4225         False\n",
      "plu4770         False\n",
      "TotalBags       False\n",
      "SmallBags        True\n",
      "LargeBags        True\n",
      "XLargeBags       True\n",
      "type            False\n",
      "region          False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(f'Is there missing data in the columns?\\n{Avo_df_copy.isna().any()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers in AveragePrice: 358\n"
     ]
    }
   ],
   "source": [
    "# Identifying outliers based on IQR in 'AveragePrice' column\n",
    "Q1 = Avo_df_copy['AveragePrice'].quantile(0.25)\n",
    "Q3 = Avo_df_copy['AveragePrice'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers_price = (Avo_df_copy['AveragePrice'] < lower_bound) | (Avo_df_copy['AveragePrice'] > upper_bound)\n",
    "\n",
    "# Print the number of outliers\n",
    "print(f\"Number of outliers in AveragePrice: {outliers_price.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalBags     0\n",
      "SmallBags     0\n",
      "LargeBags     0\n",
      "XLargeBags    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify rows with missing values\n",
    "missing_rows = Avo_df_copy[Avo_df_copy[['SmallBags', 'LargeBags', 'XLargeBags']].isnull().any(axis=1)]\n",
    "\n",
    "# Iterate over missing rows\n",
    "for index, row in missing_rows.iterrows():\n",
    "    # Fill missing values with their mean\n",
    "    Avo_df_copy.at[index, 'SmallBags'] = Avo_df_copy['SmallBags'].mean()\n",
    "    Avo_df_copy.at[index, 'LargeBags'] = Avo_df_copy['LargeBags'].mean()\n",
    "    Avo_df_copy.at[index, 'XLargeBags'] = Avo_df_copy['XLargeBags'].mean()\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "print(Avo_df_copy[['TotalBags', 'SmallBags', 'LargeBags', 'XLargeBags']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there missing data in the columns?\n",
      "Date            False\n",
      "AveragePrice    False\n",
      "TotalVolume     False\n",
      "plu4046         False\n",
      "plu4225         False\n",
      "plu4770         False\n",
      "TotalBags       False\n",
      "SmallBags       False\n",
      "LargeBags       False\n",
      "XLargeBags      False\n",
      "type            False\n",
      "region          False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(f'Is there missing data in the columns?\\n{Avo_df_copy.isna().any()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#five></a>\n",
    "## **Exploratory Data Analysis (EDA)**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Explore and visualize the data to uncover patterns, trends, and relationships.\n",
    "* **Details:** Use statistics and visualizations to explore the data. This may include histograms, box plots, scatter plots, and correlation matrices. Discuss any significant findings.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#six></a>\n",
    "## **Modeling**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Develop and train predictive or statistical models.\n",
    "* **Details:** Describe the choice of models, feature selection and engineering processes, and show how the models are trained. Include code for setting up the models and explanations of the model parameters.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#seven></a>\n",
    "## **Evaluation and Validation**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Evaluate and validate the effectiveness and accuracy of the models.\n",
    "* **Details:** Present metrics used to evaluate the models, such as accuracy, precision, recall, F1-score, etc. Discuss validation techniques employed, such as cross-validation or train/test split.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#eight></a>\n",
    "## **Final Model**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Present the final model and its performance.\n",
    "* **Details:** Highlight the best-performing model and discuss its configuration, performance, and why it was chosen over others.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#nine></a>\n",
    "## **Conclusion and Future Work**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Summarize the findings and discuss future directions.\n",
    "* **Details:** Conclude with a summary of the results, insights gained, limitations of the study, and suggestions for future projects or improvements in methodology or data collection.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#ten></a>\n",
    "## **References**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Provide citations and sources of external content.\n",
    "* **Details:** List all the references and sources consulted during the project, including data sources, research papers, and documentation for tools and libraries used.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Sections to Consider\n",
    "\n",
    "* ### Appendix: \n",
    "For any additional code, detailed tables, or extended data visualizations that are supplementary to the main content.\n",
    "\n",
    "* ### Contributors: \n",
    "If this is a group project, list the contributors and their roles or contributions to the project.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
